version: '3'

services:

  namenode1:
    image: sabaicode/hadoop_namenode:latest
    container_name: namenode1
    environment:
      - CLUSTER_NAME=bootcamp
    restart: always
    ports:
      - 9870:9870  # Old hadoop use 50070
    volumes:
      - ./hadoop_namenode1:/opt/hadoop/data/namenode
      - ./config/namenode/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/namenode/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    networks:
      - bigdata_hadoop
    # hdfs namenode -format
    # hdfs namenode -initializeSharedEdits
    command: ["hdfs", "namenode"]

  namenode2:
    image: sabaicode/hadoop_namenode:latest
    container_name: namenode2
    environment:
      - CLUSTER_NAME=bootcamp
    restart: always
    ports:
      - 9870:9870  # Old hadoop use 50070
    volumes:
      - ./hadoop_namenode2:/opt/hadoop/data/namenode
      - ./config/namenode/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/namenode/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    networks:
      - bigdata_hadoop
    # hdfs namenode -format
    # hdfs namenode -bootstrapStandby
    command: ["hdfs", "namenode"]

  journalnode1:
    image: sabaicode/hadoop_namenode:latest
    container_name: journalnode1
    # hostname: journalnode1
    volumes:
      - ./hadoop_journalnode1-data:/opt/hadoop/data/journal

  journalnode2:
    image: sabaicode/hadoop_namenode:latest
    container_name: journalnode2
    volumes:
      - ./hadoop_journalnode2-data:/opt/hadoop/data/journal

  journalnode3:
    image: sabaicode/hadoop_namenode:latest
    container_name: journalnode3
    volumes:
      - ./hadoop_journalnode3-data:/opt/hadoop/data/journal
      
  # HA setup with ZooKeeper Failover Controllers (ZKFC), 
  # this manual intervention is usually not needed, as ZKFCs will automatically
  activator:
    image: sabaicode/hadoop_namenode:latest
    container_name: activator
    command: ["hdfs", "haadmin", "-transitionToActive", "nn1"]

  # zookeeper:
  #   image: sabaicode/zookeeper:latest
  #   container_name: zookeeper
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     - ZOO_MY_ID=1
  #   command: zkServer.sh start-foreground

  datanode1:
    image: sabaicode/hadoop_datanode:latest
    container_name: datanode1
    links:
      - namenode
    restart: always
    networks:
      - bigdata_hadoop
    volumes:
      - ./hadoop_datanode/datanode1:/opt/hadoop/data/datanode
      - ./config/datanode/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/datanode/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    ports:
      - '9864:9864'
    environment:
      - SERVICE_PRECONDITION="namenode:9870"

  datanode2:
    image: sabaicode/hadoop_datanode:latest
    container_name: datanode2
    links:
      - namenode
    restart: always
    networks:
      - bigdata_hadoop
    volumes:
      - ./hadoop_datanode/datanode2:/opt/hadoop/data/datanode
      - ./config/datanode/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/datanode/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    ports:
      - '9865:9864'
    environment:
      - SERVICE_PRECONDITION="namenode:9870"

  datanode3:
    image: sabaicode/hadoop_datanode:latest
    container_name: datanode3
    links:
      - namenode
    restart: always
    networks:
      - bigdata_hadoop
    volumes:
      - ./hadoop_datanode/datanode3:/opt/hadoop/data/datanode
      - ./config/datanode/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./config/datanode/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
    ports:
      - '9866:9864'
    environment:
      - SERVICE_PRECONDITION="namenode:9870"

networks:
  bigdata_hadoop:
